{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use 2 methods to evaluate the performance of the model\n",
    "1. train_test_split (Hold-out CV)\n",
    "2. cross_val_score   (Cross validation with k-fold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate models with Train and Test  Sets\n",
    "### Why/when to Use\n",
    "1.  This technique is good for speed when using slow algorithm\n",
    "2.  It is good when there are a lot of data \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from xgboost import XGBClassifier\n",
    "from xgboost import plot_tree\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>6.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>8.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>5.000</td>\n",
       "      <td>3.000</td>\n",
       "      <td>10.000</td>\n",
       "      <td>2.000</td>\n",
       "      <td>8.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>148.000</td>\n",
       "      <td>85.000</td>\n",
       "      <td>183.000</td>\n",
       "      <td>89.000</td>\n",
       "      <td>137.000</td>\n",
       "      <td>116.000</td>\n",
       "      <td>78.000</td>\n",
       "      <td>115.000</td>\n",
       "      <td>197.000</td>\n",
       "      <td>125.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>72.000</td>\n",
       "      <td>66.000</td>\n",
       "      <td>64.000</td>\n",
       "      <td>66.000</td>\n",
       "      <td>40.000</td>\n",
       "      <td>74.000</td>\n",
       "      <td>50.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>70.000</td>\n",
       "      <td>96.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>35.000</td>\n",
       "      <td>29.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>23.000</td>\n",
       "      <td>35.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>32.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>45.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>94.000</td>\n",
       "      <td>168.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>88.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>543.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>33.600</td>\n",
       "      <td>26.600</td>\n",
       "      <td>23.300</td>\n",
       "      <td>28.100</td>\n",
       "      <td>43.100</td>\n",
       "      <td>25.600</td>\n",
       "      <td>31.000</td>\n",
       "      <td>35.300</td>\n",
       "      <td>30.500</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>0.351</td>\n",
       "      <td>0.672</td>\n",
       "      <td>0.167</td>\n",
       "      <td>2.288</td>\n",
       "      <td>0.201</td>\n",
       "      <td>0.248</td>\n",
       "      <td>0.134</td>\n",
       "      <td>0.158</td>\n",
       "      <td>0.232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>50.000</td>\n",
       "      <td>31.000</td>\n",
       "      <td>32.000</td>\n",
       "      <td>21.000</td>\n",
       "      <td>33.000</td>\n",
       "      <td>30.000</td>\n",
       "      <td>26.000</td>\n",
       "      <td>29.000</td>\n",
       "      <td>53.000</td>\n",
       "      <td>54.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         0       1        2       3        4        5       6        7  \\\n",
       "0    6.000   1.000    8.000   1.000    0.000    5.000   3.000   10.000   \n",
       "1  148.000  85.000  183.000  89.000  137.000  116.000  78.000  115.000   \n",
       "2   72.000  66.000   64.000  66.000   40.000   74.000  50.000    0.000   \n",
       "3   35.000  29.000    0.000  23.000   35.000    0.000  32.000    0.000   \n",
       "4    0.000   0.000    0.000  94.000  168.000    0.000  88.000    0.000   \n",
       "5   33.600  26.600   23.300  28.100   43.100   25.600  31.000   35.300   \n",
       "6    0.627   0.351    0.672   0.167    2.288    0.201   0.248    0.134   \n",
       "7   50.000  31.000   32.000  21.000   33.000   30.000  26.000   29.000   \n",
       "8    1.000   0.000    1.000   0.000    1.000    0.000   1.000    0.000   \n",
       "\n",
       "         8        9  \n",
       "0    2.000    8.000  \n",
       "1  197.000  125.000  \n",
       "2   70.000   96.000  \n",
       "3   45.000    0.000  \n",
       "4  543.000    0.000  \n",
       "5   30.500    0.000  \n",
       "6    0.158    0.232  \n",
       "7   53.000   54.000  \n",
       "8    1.000    1.000  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('dataset/pima-indians-diabetes.data.csv', header= None)\n",
    "df.head(10).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 768 entries, 0 to 767\n",
      "Data columns (total 9 columns):\n",
      "0    768 non-null int64\n",
      "1    768 non-null int64\n",
      "2    768 non-null int64\n",
      "3    768 non-null int64\n",
      "4    768 non-null int64\n",
      "5    768 non-null float64\n",
      "6    768 non-null float64\n",
      "7    768 non-null int64\n",
      "8    768 non-null int64\n",
      "dtypes: float64(2), int64(7)\n",
      "memory usage: 54.1 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>3.845052</td>\n",
       "      <td>120.894531</td>\n",
       "      <td>69.105469</td>\n",
       "      <td>20.536458</td>\n",
       "      <td>79.799479</td>\n",
       "      <td>31.992578</td>\n",
       "      <td>0.471876</td>\n",
       "      <td>33.240885</td>\n",
       "      <td>0.348958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>3.369578</td>\n",
       "      <td>31.972618</td>\n",
       "      <td>19.355807</td>\n",
       "      <td>15.952218</td>\n",
       "      <td>115.244002</td>\n",
       "      <td>7.884160</td>\n",
       "      <td>0.331329</td>\n",
       "      <td>11.760232</td>\n",
       "      <td>0.476951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.078000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>27.300000</td>\n",
       "      <td>0.243750</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>117.000000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>30.500000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>0.372500</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>140.250000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>127.250000</td>\n",
       "      <td>36.600000</td>\n",
       "      <td>0.626250</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>199.000000</td>\n",
       "      <td>122.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>846.000000</td>\n",
       "      <td>67.100000</td>\n",
       "      <td>2.420000</td>\n",
       "      <td>81.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                0           1           2           3           4           5  \\\n",
       "count  768.000000  768.000000  768.000000  768.000000  768.000000  768.000000   \n",
       "mean     3.845052  120.894531   69.105469   20.536458   79.799479   31.992578   \n",
       "std      3.369578   31.972618   19.355807   15.952218  115.244002    7.884160   \n",
       "min      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "25%      1.000000   99.000000   62.000000    0.000000    0.000000   27.300000   \n",
       "50%      3.000000  117.000000   72.000000   23.000000   30.500000   32.000000   \n",
       "75%      6.000000  140.250000   80.000000   32.000000  127.250000   36.600000   \n",
       "max     17.000000  199.000000  122.000000   99.000000  846.000000   67.100000   \n",
       "\n",
       "                6           7           8  \n",
       "count  768.000000  768.000000  768.000000  \n",
       "mean     0.471876   33.240885    0.348958  \n",
       "std      0.331329   11.760232    0.476951  \n",
       "min      0.078000   21.000000    0.000000  \n",
       "25%      0.243750   24.000000    0.000000  \n",
       "50%      0.372500   29.000000    0.000000  \n",
       "75%      0.626250   41.000000    1.000000  \n",
       "max      2.420000   81.000000    1.000000  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features :  [0, 1, 2, 3, 4, 5, 6, 7]\n",
      "Label : 8\n"
     ]
    }
   ],
   "source": [
    "features = df.columns.to_list()[:8]\n",
    "label = df.columns.to_list()[-1]\n",
    "print(\"Features : \",features)\n",
    "print(\"Label :\", label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df[label].value_counts().plot(kind='bar')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[features]\n",
    "y = df[label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((514, 8), (514,), (254, 8), (254,))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size =0.33, random_state = 7 )\n",
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\X168586\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:27:46] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Model : \n",
      " XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
      "              importance_type='gain', interaction_constraints='',\n",
      "              learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
      "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
      "              n_estimators=100, n_jobs=8, num_parallel_tree=1,\n",
      "              objective='binary:logistic', random_state=0, reg_alpha=0,\n",
      "              reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
      "              tree_method='exact', use_label_encoder=True,\n",
      "              validate_parameters=1, verbosity=None)\n",
      "Accuracy:  0.7401574803149606\n"
     ]
    }
   ],
   "source": [
    "model = XGBClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "print(\"Model : \\n\", model)\n",
    "y_pred = model.predict(X_test)\n",
    "score = accuracy_score(y_test,y_pred)\n",
    "print(\"Accuracy: \", score)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate Models With k-Fold Cross-Validation\n",
    "### Why/When To Use\n",
    "1. It is more accurate because the algorithm is trained and evaluated multiple times on different data.\n",
    "2. It is good when there are not a lot of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\X168586\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:15:00] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:15:00] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:15:00] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:15:00] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:15:01] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Model\n",
      " XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None, gamma=None,\n",
      "              gpu_id=None, importance_type='gain', interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              objective='binary:logistic', random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, use_label_encoder=True,\n",
      "              validate_parameters=None, verbosity=None)\n",
      "[0.73376623 0.74675325 0.74025974 0.78431373 0.75816993]\n",
      "accuracy :  0.7526525761819879\n"
     ]
    }
   ],
   "source": [
    "xgb_model = XGBClassifier()\n",
    "# cv_results = cross_val_score(xgb_model, X, y, scoring = 'neg_mean_squared_error', cv = 5)\n",
    "# rmse = np.sqrt(-1*cv_results.mean())\n",
    "# print(\"\\nRMSE : \", rmse)\n",
    "\n",
    "cv_results = cross_val_score(xgb_model, X, y, cv = 5)\n",
    "print(\"Model\\n\", xgb_model)\n",
    "print(cv_results)\n",
    "print(\"accuracy : \", cv_results.mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
